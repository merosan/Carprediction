{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import platform\n",
    "import socket\n",
    "from platform import python_version\n",
    "from datetime import datetime\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Show current working directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('merged_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['Temperatur (Â°C)',\n",
    "                                                        'Niederschlag',\n",
    "                                                        'Richtung',\n",
    "                                                        'Luftfeuchtigkeit (%Hr)',\n",
    "                                                        'Luftdruck (hPa)',\n",
    "                                                        'holiday']], \n",
    "                                                    df['AnzFahrzeuge'], \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=42)\n",
    "# Show X_train\n",
    "print('X_train:')\n",
    "print(X_train.head(), '\\n')\n",
    "\n",
    "# Show y_train\n",
    "print('y_train:')\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "y_predicted = lin_reg.predict(X_test)\n",
    "\n",
    "y_residuals = y_test - y_predicted\n",
    "\n",
    "mse = mean_squared_error(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(8,4))\n",
    "n, bins, patches = plt.hist(x=y_residuals, \n",
    "                            bins=20, \n",
    "                            color='blue',\n",
    "                            alpha=0.5\n",
    "                   )\n",
    "\n",
    "# Set labels\n",
    "plt.xlabel('residuals', fontsize=10, labelpad=10)\n",
    "plt.ylabel('frequency', fontsize=10, labelpad=10)\n",
    "plt.title('Histogram of model residuals', fontsize=12, pad=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train linear_model = LinearRegression()\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "scores = cross_val_score(linear_model, X_train, y_train, scoring=\"neg_root_mean_squared_error\", cv=5)\n",
    "print('--{}--'.format(linear_model))\n",
    "print(scores)\n",
    "print(np.mean(scores)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.get_params()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_model = Pipeline([\n",
    "                                (\"polynomial_features\", PolynomialFeatures(degree=2)),\n",
    "                                (\"linear_regression\", LinearRegression()),\n",
    "                            ])\n",
    "\n",
    "scores = cross_val_score(polynomial_model, X_train, y_train, scoring=\"neg_root_mean_squared_error\", cv=5)\n",
    "print('--{}--'.format(polynomial_model))\n",
    "print(scores)\n",
    "print(np.mean(scores)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "'polynomial_features__degree': [2, 4, 6, 8], \n",
    "'polynomial_features__include_bias': [True, False],\n",
    "}\n",
    "\n",
    "grid_search_pl = GridSearchCV(polynomial_model, param_grid, cv=5, scoring='neg_root_mean_squared_error', verbose=2) # add param verbose = 2 to see the state\n",
    "grid_search_pl.fit(X_train, y_train)\n",
    "print(grid_search_pl.best_estimator_)\n",
    "print(grid_search_pl.best_params_)\n",
    "print(grid_search_pl.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "scores = cross_val_score(randomforest_model, X_train, y_train, scoring=\"neg_root_mean_squared_error\", cv=5)\n",
    "print('--{}--'.format(randomforest_model))\n",
    "print(scores)\n",
    "print(np.mean(scores)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {'max_depth': [25, 30, 35],\n",
    "'max_features': [7, 9]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(randomforest_model, param_grid, cv=5, scoring='neg_root_mean_squared_error', verbose=2) # add param verbose = 2 to see the state\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "print(grid_search_rf.best_estimator_)\n",
    "print(grid_search_rf.best_params_)\n",
    "print(grid_search_rf.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Modell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "decisiontree_model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "scores = cross_val_score(decisiontree_model, X_train, y_train, scoring=\"neg_root_mean_squared_error\", cv=5)\n",
    "print('--{}--'.format(decisiontree_model))\n",
    "print(scores)\n",
    "print(np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "decisiontree_model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [90, 100, 110],\n",
    "    'max_features': [6, 9]\n",
    "}\n",
    "\n",
    "grid_search_dt = GridSearchCV(decisiontree_model, param_grid, cv=5, scoring='neg_root_mean_squared_error', verbose=2)\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "print(grid_search_dt.best_estimator_)\n",
    "print(grid_search_dt.best_params_)\n",
    "print(grid_search_dt.best_score_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "gradientboost_model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "scores = cross_val_score(gradientboost_model, X_train, y_train, scoring=\"neg_root_mean_squared_error\", cv=5)\n",
    "print('--{}--'.format(gradientboost_model))\n",
    "print(scores)\n",
    "print(np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gradientboost_model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [10, 15, 20], \n",
    "    'max_features': [5, 7, 9]\n",
    "}\n",
    "\n",
    "grid_search_gb = GridSearchCV(gradientboost_model, param_grid, cv=5, scoring='neg_root_mean_squared_error', verbose=2)\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "print(grid_search_gb.best_estimator_)\n",
    "print(grid_search_gb.best_params_)\n",
    "print(grid_search_gb.best_score_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assume you have a trained GridSearchCV model named 'grid_search_gb' from the previous code\n",
    "\n",
    "# Extract the best fitted model from the GridSearchCV\n",
    "best_model = grid_search_gb.best_estimator_\n",
    "\n",
    "# Extract the feature importances from the best fitted model\n",
    "feature_importance = best_model.feature_importances_\n",
    "\n",
    "# Sort the feature importances in descending order\n",
    "sorted_indices = np.argsort(feature_importance)[::-1]\n",
    "\n",
    "# Extract the names of the features in the correct order\n",
    "feature_names = X_train.columns[sorted_indices]\n",
    "\n",
    "# Extract the feature importances in the correct order\n",
    "sorted_importance = feature_importance[sorted_indices]\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(feature_names)), sorted_importance, align='center')\n",
    "plt.yticks(range(len(feature_names)), feature_names)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Gradient Boosting Regressor - Feature Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Erstelle das Decision Tree-Modell\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "# Trainiere das Modell mit den Trainingsdaten\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Mache Vorhersagen auf den Trainingsdaten\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Berechne den RMSE auf den Trainingsdaten\n",
    "rmse_train = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "\n",
    "# Mache Vorhersagen auf den Testdaten\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Berechne den RMSE auf den Testdaten\n",
    "rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "# Ausgabe der RMSE-Werte\n",
    "print(\"Train RMSE:\", rmse_train)\n",
    "print(\"Test RMSE:\", rmse_test)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definieren Sie den Entscheidungsbaum-Regressor\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "# Definieren Sie den Parametergitter\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Erstellen Sie die Grid Search\n",
    "grid_search = GridSearchCV(estimator=tree, param_grid=param_grid, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "# FÃ¼hren Sie die Grid Search mit den Trainingsdaten durch\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Zeigen Sie die besten Parameterkombinationen an\n",
    "print(\"Beste Parameterkombination: \", grid_search.best_params_)\n",
    "\n",
    "# Rufen Sie das Modell mit den besten Parametern ab\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Bewertung des besten Modells auf den Testdaten\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Test RMSE mit besten Parametern: \", test_rmse)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Definieren Sie den Gradient Boosting-Regressor\n",
    "gb_model = GradientBoostingRegressor()\n",
    "\n",
    "# Trainieren Sie das Modell mit den Trainingsdaten\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersage auf den Trainingsdaten\n",
    "y_train_pred = gb_model.predict(X_train)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Train RMSE: \", train_rmse)\n",
    "\n",
    "# Vorhersage auf den Testdaten\n",
    "y_test_pred = gb_model.predict(X_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "print(\"Test RMSE: \", test_rmse)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Definieren Sie den Gradient Boosting-Regressor\n",
    "gb_model = GradientBoostingRegressor()\n",
    "\n",
    "# Definieren Sie die Parameter, die Sie optimieren mÃ¶chten\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Initialisieren Sie die GridSearchCV mit dem Gradient Boosting-Regressor und dem Parametergitter\n",
    "grid_search = GridSearchCV(estimator=gb_model, param_grid=param_grid, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "# FÃ¼hren Sie die Gittersuche durch, um die besten Parameter zu finden\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Rufen Sie die besten Parameter ab\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Beste Parameter: \", best_params)\n",
    "\n",
    "# Trainieren Sie das Modell mit den besten Parametern\n",
    "best_gb_model = GradientBoostingRegressor(**best_params)\n",
    "best_gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersage auf den Trainingsdaten\n",
    "y_train_pred = best_gb_model.predict(X_train)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Train RMSE: \", train_rmse)\n",
    "\n",
    "# Vorhersage auf den Testdaten\n",
    "y_test_pred = best_gb_model.predict(X_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "print(\"Test RMSE: \", test_rmse)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
